{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"IBMDVS128GestureAttacks.ipynb","provenance":[],"collapsed_sections":["mF7QOb-0g9Xz","lLz9ZZ65m2Og","f4mqdcbvm9ao","ZwGV51yGRtic","7NZK1U370T14","irzRDAXELtaL","sxq2bR921uDQ","_8faoP9vw-la","e1grpPmF4Bqg","duq1oc3bTvHx","JYZuKPiGPa5H","JGZvJeE-Q6D0","IipMla4tnhgA","mkbQLPIt4k7g","eSNvcA-z4eXg","o_ZWLMTlnhgA","0Hze_ZxsMTBN","HG9jaRtt6T4K"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mF7QOb-0g9Xz"},"source":["# Install SlayerPytorch on Colab\n","After the installations the runtime needs to be restarted. \n","```\n","exit()\n","```\n","Will restart the runtime without deleting files. The runtime will automatically start. And if you press \"run all\" the run is not interrupted and works till the end."]},{"cell_type":"code","metadata":{"id":"aSnbF5w-jTGQ"},"source":["!git clone https://github.com/bamsumit/slayerPytorch\n","!pip install ninja\n","exit()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HhdpSnPWkG8r"},"source":["%cd slayerPytorch/\n","!python setup.py install\n","exit()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7F0vk1qah9Dh"},"source":["Test to verify if everything went well with the installation"]},{"cell_type":"code","metadata":{"id":"35lkjdNJl20b"},"source":["%cd slayerPytorch/test/\n","!python -m  unittest"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lLz9ZZ65m2Og"},"source":["# Network Configuration"]},{"cell_type":"code","metadata":{"id":"KutIWXV6msjx"},"source":["!unzip -q '/content/drive/MyDrive/Test.zip' -d '/content/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZGmhuRpatzVK"},"source":["import sys, os\n","CURRENT_TEST_DIR = os.getcwd()\n","sys.path.append(CURRENT_TEST_DIR + \"/../../src\")\n","\n","from datetime import datetime\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from IPython.display import HTML\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import slayerSNN as snn\n","#from learningStats import learningStats\n","from IPython.display import HTML\n","import time\n","import shutil\n","\n","def save_ckp(state, is_best_loss, is_best_acc, checkpoint_dir, best_model_dir):\n","    f_path = checkpoint_dir+'checkpoint.pt'\n","    torch.save(state, f_path)\n","    if is_best_loss:\n","        best_fpath = best_model_dir+'best_model.pt'\n","        shutil.copyfile(f_path, best_fpath)\n","    if is_best_acc:\n","        acc_fpath =  best_model_dir+'best_acc.pt'\n","        shutil.copyfile(f_path, acc_fpath)\n","        \n","def load_ckp(checkpoint_fpath, model, optimizer):\n","    checkpoint = torch.load(checkpoint_fpath)\n","    model.load_state_dict(checkpoint['state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    return model, optimizer, checkpoint['epoch']\n","\n","actionName = [\n","    'hand_clapping',\n","    'right_hand_wave',\n","    'left_hand_wave',\n","    'right_arm_clockwise',\n","    'right_arm_counter_clockwise',\n","    'left_arm_clockwise', \n","    'left_arm_counter_clockwise',\n","    'arm_roll',\n","    'air_drums',\n","    'air_guitar',\n","    'other_gestures',\n","]\n","\n","# Define dataset module\n","class IBMGestureDataset(Dataset):\n","    def __init__(self, datasetPath, sampleFile, samplingTime, sampleLength):\n","        self.path = datasetPath \n","        self.samples = np.loadtxt(sampleFile).astype('int')\n","        self.samplingTime = samplingTime\n","        self.nTimeBins    = int(sampleLength / samplingTime)\n","\n","    def __getitem__(self, index):\n","        # Read inoput and label\n","        inputIndex  = self.samples[index, 0]\n","        classLabel  = self.samples[index, 1]\n","        # Read input spike\n","        inputSpikes = snn.io.readNpSpikes(\n","                        self.path + str(inputIndex.item()) + '.npy'\n","                        ).toSpikeTensor(torch.zeros((2,128,128,self.nTimeBins)),\n","                        samplingTime=self.samplingTime)\n","        # Create one-hot encoded desired matrix\n","        desiredClass = torch.zeros((11, 1, 1, 1))\n","        desiredClass[classLabel,...] = 1\n","        \n","        return inputSpikes, desiredClass, classLabel\n","\n","    def __len__(self):\n","        return self.samples.shape[0]\n","\t\t\n","# Define the network\n","class Network(torch.nn.Module):\n","    def __init__(self, netParams):\n","        super(Network, self).__init__()\n","        # initialize slayer\n","        slayer = snn.loihi(netParams['neuron'], netParams['simulation'])\n","        self.slayer = slayer\n","        # define network functions\n","        self.conv1 = slayer.conv(2, 16, 5, padding=2, weightScale=10)\n","        self.conv2 = slayer.conv(16, 32, 3, padding=1, weightScale=50)\n","        self.pool1 = slayer.pool(4)\n","        self.pool2 = slayer.pool(2)\n","        self.pool3 = slayer.pool(2)\n","        self.fc1   = slayer.dense((8*8*32), 512)\n","        self.fc2   = slayer.dense(512, 11)\n","        self.drop  = slayer.dropout(0.1)\n","\n","    def forward(self, spikeInput):\n","        spike = self.slayer.spikeLoihi(self.pool1(spikeInput )) # 32, 32, 2\n","        spike = self.slayer.delayShift(spike, 1)\n","        \n","        spike = self.drop(spike)\n","        spike = self.slayer.spikeLoihi(self.conv1(spike)) # 32, 32, 16\n","        spike = self.slayer.delayShift(spike, 1)\n","        \n","        spike = self.slayer.spikeLoihi(self.pool2(spike)) # 16, 16, 16\n","        spike = self.slayer.delayShift(spike, 1)\n","        \n","        spike = self.drop(spike)\n","        spike = self.slayer.spikeLoihi(self.conv2(spike)) # 16, 16, 32\n","        spike = self.slayer.delayShift(spike, 1)\n","        \n","        spike = self.slayer.spikeLoihi(self.pool3(spike)) #  8,  8, 32\n","        spike = spike.reshape((spike.shape[0], -1, 1, 1, spike.shape[-1]))\n","        spike = self.slayer.delayShift(spike, 1)\n","        \n","        spike = self.drop(spike)\n","        spike = self.slayer.spikeLoihi(self.fc1  (spike)) # 512\n","        spike = self.slayer.delayShift(spike, 1)\n","        \n","        spike = self.slayer.spikeLoihi(self.fc2  (spike)) # 11\n","        spike = self.slayer.delayShift(spike, 1)\n","        \n","        return spike\n","\n","\n","if __name__ == '__main__':\n","\tnetParams = snn.params('/content/slayerPytorch/exampleLoihi/03_IBMGesture/network.yaml')\n","\t\n","\t# Define the cuda device to run the code on.\n","\tdevice = torch.device('cuda')\n","\t# deviceIds = [2, 3]\n","\n","\t# Create network instance.\n","\tnet = Network(netParams).to(device)\n","\t# net = torch.nn.DataParallel(Network(netParams).to(device), device_ids=deviceIds)\n","\n","\t# Create snn loss instance.\n","\terror = snn.loss(netParams, snn.loihi).to(device)\n","\n","\t# Define optimizer module.\n","\t# optimizer = torch.optim.Adam(net.parameters(), lr = 0.01, amsgrad = True)\n","\toptimizer = snn.utils.optim.Nadam(net.parameters(), lr = 0.01, amsgrad = True)\n","\n","\t#Dataset and dataLoader instances.\n","\n","\ttestingSet = IBMGestureDataset(datasetPath =\"/content/MyDrive/Test/\", \n","\t\t\t\t\t\t\t\t\tsampleFile  = \"/content/drive/MyDrive/Test/test.txt\",\n","\t\t\t\t\t\t\t\t\tsamplingTime= 1.0,\n","\t\t\t\t\t\t\t\t\tsampleLength= 1450)\n","\ttestLoader = DataLoader(dataset=testingSet, batch_size=1, shuffle=False, num_workers=1)\n","  \n","\ti=0\n","\n","\t# Learning stats instance.\n","\tstats = snn.utils.stats()\n","\tckp_path = \"drive/My Drive/best/check.pt\"\n","\tnet, optimizer, start_epoch = load_ckp(ckp_path, net, optimizer)\n","\tstart_epoch\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f4mqdcbvm9ao"},"source":["# Adversarial Attacks\n","Collection of 5 different Adversarial Attacks"]},{"cell_type":"markdown","metadata":{"id":"ZwGV51yGRtic"},"source":["##Gradient Based Attack"]},{"cell_type":"code","metadata":{"id":"N2ed6a14Fv7o"},"source":["testingSet = IBMGestureDataset(datasetPath  =  '/content/Test/', \n","                              sampleFile  ='/content/Test/test.txt',\n","                              samplingTime=1.0,\n","                              sampleLength=1450)\n","testLoader = DataLoader(dataset=testingSet, batch_size=1, shuffle=False, num_workers=4)\n","\n","import argparse\n","import numpy as np\n","import pdb \n","import torch, torchvision\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","\n","\n","def update(x,y,t,s,A):\n","  for i in range(x-s,x+s+1):\n","     for j in range(y-s,y+s+1):\n","        if not(i==x and j==y) and i>0 and j>0 and i<128 and j<128:\n","\t        A[i][j] = t\n","    \n","\n","#Select the device to run the code \n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print ('Device: ' + str(device))\n","\n","def calc_gradients(\n","\t\ttest_dataloader,\n","\t\tmodel,\n","\t\tmax_iter,\n","\t\tlearning_rate,\n","    samples,\n","\t\tfilter_on,\n","\t\ts,\n","\t\tT,\n","\t\ttargets=None,\n","\t\tweight_loss2=1,\n","\t\tbatch_size=1,\n","\t\tseq_len=40,):\n","\t\n","\t#Define the modifier and the optimizer\n","\n","  min_loss = 1e-5\n","  prev_loss = 1e-5\n","  correct = np.zeros(max_iter)\t\n","  for batch_index, (input_image, input_target, input_label) in enumerate(test_dataloader):\n","\n","    modif = torch.Tensor(1, seq_len, 2, 128, 128).fill_(1).to(device)\n","    modifier = torch.nn.Parameter(modif, requires_grad=True)\n","    optimizer = torch.optim.Adam([modifier], lr=learning_rate)\n","\n","    if batch_index>samples:\n","      break\n","    model.eval()\n","    with torch.no_grad():\t\n","      input_image, input_label = input_image.to(device), input_label.to(device)\n","\n","    #Clean video prediction \n","    print(f'Batch Number: {batch_index}/{len(test_dataloader)}')\n","    print('------------------prediction for clean video-------------------')\n","    input_image = Variable(input_image, requires_grad=True)\n","    output = model.forward(input_image)\n","    pre_label= snn.predict.getClass(output)\n","    p = torch.nn.Softmax(dim=1)\t\t\n","    print (f'Prediction: {pre_label}, Original_label: {input_label.cpu().numpy()}')\n","\n","    print('------------------prediction for adversarial video-------------------')\n","\n","    min_in = input_image.min().detach() #0\n","    max_in = input_image.max().detach() #1\n","\n","    for iiter in range(max_iter):\n","      with open ('/content/modifier.txt','w') as file:\n","        file.write(str(modifier))      \n","      print(modifier[0,0,0,0,0])\t\t\t\n","      input_image = Variable(input_image, requires_grad=True)\n","      #model.lstm.reset_hidden_state()\n","      \n","      #Frames to be perturbed\n","      indicator = [0]*1450\n","      for i,x in enumerate(indicator):\n","        if (i>399 and i<510) or (i>724 and i<870) or (i>1199 and i< 1275):\n","          x=1\n","    \n","      #Perturbating the frames\n","\n","      input_image=torch.reshape(input_image, (1,1450,2,128,128)) ###\n","      true_image = modifier[0,0,:,:,:]+input_image[0,0,:,:,:]\n","      true_image = torch.unsqueeze(true_image, 0)\n","      \n","      for ll in range(seq_len-1): #seq_len =1450\n","        if indicator[ll+1] == 1:\n","          mask_temp = modifier[0,ll+1,:,:,:]+input_image[0,ll+1,:,:,:]\n","        else:\n","          mask_temp = input_image[0,ll+1,:,:,:]\n","        mask_temp = torch.unsqueeze(mask_temp,0)\n","        true_image = torch.cat((true_image, mask_temp),0)\n","\n","      #######\t\t Filter section \t######\n","      if filter_on :\n","        img = torch.reshape(true_image, (2,128,128,1450)).cpu().detach()\n","        TD = snn.io.spikeArrayToEvent(img.numpy(), samplingTime=1)\n","        snn.io.encodeNpSpikes(\"/content/drive/My Drive/temp/img.npy\", TD)\n","        data= np.load('/content/drive/My Drive/temp/img.npy'.format(i))\n","        data= data[data[:,3].argsort()] #sort elements by timestamp\n","        temp=np.zeros((128,128))\n","        real=[]\n","        for d in data:\n","          update(int(d[0]),int(d[1]),d[3],s,temp)\n","          if d[3]-temp[int(d[0])][int(d[1])]<T:\n","            real.append(d)\n","        real=np.stack(real, axis=0 )\n","        with open(\"/content/drive/My Drive/temp/fil.npy\", \"wb\") as f:\n","          np.save(f,real)\n","        true_image = snn.io.readNpSpikes(\n","            \"/content/drive/My Drive/temp/fil.npy\"\n","            ).toSpikeTensor(torch.zeros((2,128,128,1450)),\n","            samplingTime=1.0)\n","        true_image =  true_image.to(device)\n","      true_image = torch.reshape(true_image, (1,1450,2,128,128))\t\t\t\n","      #######\t\t End Filter Section \t #######\t\t\n","     \n","      #Prediction on the adversarial video\n","      output = model.forward(torch.reshape(true_image, (1,2,128,128,1450)))\n","      pre_label = snn.predict.getClass(output)\n","      numSpikes = torch.sum(output, 4, keepdim=True)\n","      print (f'numSpikes: {numSpikes[0,:,0,0]}, maxSpikes : {torch.max(numSpikes)}')\n","      numSpikes= torch.div(numSpikes,torch.max(numSpikes))\t\n","      probs= p(numSpikes.reshape((numSpikes.shape[0], -1)))\t\n","\n","      #extracting the probability of true label \n","      zero_array = torch.zeros(11).to(device) \n","      zero_array[input_label.cpu()] = 1\n","      true_label_onehot = probs*zero_array\n","      true_label_prob = torch.sum(true_label_onehot, 1)\n","\n","      if pre_label.numpy()==input_label.cpu().numpy() : correct[iiter]+=1\n","\n","      #Loss\n","      if targets is None:\n","        loss1 = -torch.log(1 - true_label_prob + 1e-6)\n","      else:\n","        loss1 = -torch.log(true_label_prob + 1e-6)\n","      loss1 = torch.mean(loss1)\n","      input_image=torch.reshape(input_image, (1,1450,2,128,128))\n","      loss2 =  weight_loss2*torch.sum(torch.sqrt(torch.mean(torch.pow((true_image-input_image+1e-21), 2), dim=0).mean(dim=2).mean(dim=2).mean(dim=1)))\n","      loss = loss1 +  loss2\n","      optimizer.zero_grad()\n","      loss.backward() \n","      optimizer.step()\n","      if True: #iiter % max_iter == 0: \n","        print (f'Probability for ground truth label : {true_label_prob.detach().cpu().numpy()}')\n","        if prev_loss < loss : \n","          print(f'Iteration: [{iiter+1}/{max_iter}], Loss: {loss}(\\u25b2), Loss1: {loss1}, Loss2: {loss2}\\n\\n')\n","        elif prev_loss > loss: \n","          print(f'Iteration: [{iiter+1}/{max_iter}], Loss: {loss}(\\u25bc), Loss1: {loss1}, Loss2: {loss2}\\n\\n')\n","        else: \n","          print(f'Iteration: [{iiter+1}/{max_iter}], Loss: {loss}, Loss1: {loss1}, Loss2: {loss2}\\n\\n')\n","      prev_loss = loss\n","\n","      break_condition = False\n","      if loss < min_loss:\n","        if torch.abs(loss-min_loss) < 0.0001:\n","            break_condition = True\n","            print ('Aborting early!')\n","        min_loss = loss\n","\n","      # Empty cache\n","      if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    # Save adversarial dataset as spike events\n","    image = torch.reshape(true_image, (2,128,128,1450)).cpu().detach()\n","    TD = snn.io.spikeArrayToEvent(image.numpy(), samplingTime=1)\n","    snn.io.encodeNpSpikes(\"/content/prova/{}.npy\".format(batch_index), TD)\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\t\n","  print(correct)\n","\n","\n","def main(net):\n","\n","  args = {\n","      'description': 'Sparse Adversarial Perturbations',\n","      'num_iter': 5,\n","      'learning_rate': 1,\n","      'samples': 264,\n","\t\t\t'filter_on': False,\n","\t\t\t's': 2,\n","\t\t\t'T': 5,\n","      'target': None,\n","      'weight_loss2': 0,\n","      'split_path': None,\n","      'split_number': 1,\n","      'img_dim': 128,\n","      'channels': 2,\n","\t\t\t}\n","  seq_len = 1450 #number of frames in a video\n","  batch_size = 1\n","  targets = None\n","  image_shape = (args['channels'], args['img_dim'], args['img_dim'])\n","  net = net.to(device)\n","  net.train()\n","  print('Model Loaded Successfully!')\n","\t#Call the function to generate the adversarial videos\n","  calc_gradients(\n","\ttestLoader,\n","\tnet,\n","\targs['num_iter'],\n","\targs['learning_rate'],\n","  args['samples'],\n","\targs['filter_on'],\n","\targs['s'],\n","\targs['T'],\n","\ttargets,\n","\targs['weight_loss2'],\n","\tbatch_size,\n","\tseq_len,\n","\t)\n","\n","if __name__ == '__main__':\n","\tmain(net)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7NZK1U370T14"},"source":["##Frame Attack"]},{"cell_type":"code","metadata":{"id":"iRT1D3Ag1huv"},"source":["import numpy as np\n","import torch\n","import time\n","\n","def cornerGen(x=0,y=0, N=128,T=1450):\n","  corner = torch.zeros((N,N,T))\n","  for i in range(N):\n","    for j in range(N):\n","      if i==x or i == N-1-x or j==y or j== N-1-y :\n","        corner[i,j,:]=1       \n","\n","  return corner.expand(2,N,N,T)\n","\n","testSet = IBMGestureDataset(datasetPath  =  '/content/Test/', \n","                              sampleFile  ='/content/Test/test.txt',\n","                              samplingTime=1.0,\n","                              sampleLength=1450)\n","testLoader = DataLoader(dataset=testSet, batch_size=1, shuffle=False, num_workers=4) \n","\n","samples = [i for i in range(264)]\n","stats.testing.reset()\n","\n","N=128\n","x=0\n","y=0\n","\n","start=time.time()\n","\n","temp= list(samples)\n","corner= cornerGen(x,y)\n","for i  in temp:\n","\n","  input,target,label=testSet[i]\n","  \n","  adv= input.unsqueeze(dim=0)+corner\n","  \n","  # Save adversarial dataset as spike events\n","  image = torch.reshape(adv, (2,N,N,1450))\n","  TD = snn.io.spikeArrayToEvent(image.numpy(), samplingTime=1)\n","  snn.io.encodeNpSpikes(\"/content/prova/{}.npy\".format(i), TD)\n","print(time.time()-start)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"irzRDAXELtaL"},"source":["##Corner Attack\n"]},{"cell_type":"code","metadata":{"id":"EG28fm-KpZmt"},"source":["import numpy as np\n","import torch\n","import time\n","\n","def cornerGen(x=0,y=0,left=False, N=128,T=1450):\n","  corner = torch.zeros((N,N,T))\n","  for i in range(N):\n","    for j in range(N):\n","      if left:\n","        if (i==x and j<y):\n","          corner[i,j,:]=1\n","      else:\n","        if (i==x and j>=N-y):\n","          corner[i,j,:]=1        \n","\n","  return corner.expand(2,N,N,T)\n","\n","testSet = IBMGestureDataset(datasetPath  =  '/content/Test/', \n","                              sampleFile  ='/content/Test/test.txt',\n","                              samplingTime=1.0,\n","                              sampleLength=1450)\n","testLoader = DataLoader(dataset=testSet, batch_size=1, shuffle=False, num_workers=4) \n","\n","samples = [i for i in range(264)]\n","stats.testing.reset()\n","it=0\n","N=128\n","flag=0\n","left = 1\n","x=0\n","y=2\n","max_y=2\n","start=time.time()\n","while samples and x<N and y<N:\n","  temp= list(samples)\n","  corner= cornerGen(x,y,left)\n","  for i  in temp:\n","\n","    input,target,label=testSet[i]\n","    \n","    adv= input.unsqueeze(dim=0)+corner\n","    with torch.no_grad():\n","      adv  = adv.to(device)\n","      target = target.to(device) \n","\n","    output = net.forward(adv)\n","    if (snn.predict.getClass(output) != label):\n","      #print(f' Sample {i} , {label}')\n","      try: \n","        samples.remove(i)\n","      except:\n","        print(f'{i} not in list')\n","      # Save adversarial dataset as spike events\n","      image = torch.reshape(adv, (2,N,N,1450)).cpu().detach()\n","      TD = snn.io.spikeArrayToEvent(image.numpy(), samplingTime=1)\n","      snn.io.encodeNpSpikes(\"/content/prova/{}.npy\".format(i), TD)\n","  print(f'remaining samples {len(samples)}, x = {x}, y={y}', 'left' if left else 'right')\n","\n","  if flag:\n","    x= 0\n","    flag^=1\n","    left^=1\n","    if left:\n","      if y==2:\n","        y=5\n","      else:\n","        y+=4\n","  else:\n","    x= N-1\n","    flag^=1\n","\n","print(time.time()-start)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sxq2bR921uDQ"},"source":["##Dash Attack \n"]},{"cell_type":"code","metadata":{"id":"AZ-cxTpdJH8N"},"source":["import numpy as np\n","import torch\n","import time\n","\n","def cornerGen(x=0,y=0,left=False, N=128,T=1450):\n","  corner = torch.zeros((N,N,T))\n","  for i in range(N):\n","    for j in range(N):\n","      if left:\n","        if (i==x) and (j==y or j== y-1):\n","          corner[i,j,:]=1\n","      else:\n","        if (i==x) and (j==N-y or j== N-y+1):\n","          corner[i,j,:]=1        \n","\n","  return corner.expand(2,N,N,T)\n","\n","testSet = IBMGestureDataset(datasetPath  =  '/content/Test/', \n","                              sampleFile  ='/content/Test/test.txt',\n","                              samplingTime=1.0,\n","                              sampleLength=1450)\n","testLoader = DataLoader(dataset=testSet, batch_size=1, shuffle=False, num_workers=4) \n","\n","samples = [i for i in range(264)]\n","stats.testing.reset()\n","it=0\n","N=128\n","flag=0\n","left = 1\n","x=0\n","y=2\n","max_y=2\n","start=time.time()\n","while samples and x<N and y<N:\n","  temp= list(samples)\n","  corner= cornerGen(x,y,left)\n","  for i  in temp:\n","\n","    input,target,label=testSet[i]\n","    \n","    adv= input.unsqueeze(dim=0)+corner\n","    with torch.no_grad():\n","      adv  = adv.to(device)\n","      target = target.to(device) \n","\n","    output = net.forward(adv)\n","    if (snn.predict.getClass(output) != label):\n","      #print(f' Sample {i} , {label}')\n","      try: \n","        samples.remove(i)\n","      except:\n","        print(f'{i} not in list')\n","      # Save adversarial dataset as spike events\n","      image = torch.reshape(adv, (2,N,N,1450)).cpu().detach()\n","      TD = snn.io.spikeArrayToEvent(image.numpy(), samplingTime=1)\n","      snn.io.encodeNpSpikes(\"/content/prova/{}.npy\".format(i), TD)\n","  print(f'remaining samples {len(samples)}, x = {x}, y={y}', 'left' if left else 'right')\n","\n","  if flag:\n","    x= 0\n","    flag^=1\n","    left^=1\n","    if left:\n","      if y==2:\n","        y=5\n","      else:\n","        y+=4\n","  else:\n","    x= N-1\n","    flag^=1\n","\n","print(time.time()-start)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_8faoP9vw-la"},"source":["## MF-Aware Dash Attack"]},{"cell_type":"code","metadata":{"id":"EdJRsxrow-lj"},"source":["import numpy as np\n","import torch\n","import time\n","\n","\n","def dashGen(x=0,y=2,left=False,th0=10, N=128,T=1450,):\n","  th=th0\n","  dash = torch.zeros((2,N,N,T))\n","  for t in range(T):\n","    for i in range(N):\n","      for j in range(N):\n","        if left:\n","          if (i==x  and (j==y or j== y-1) and t<th):\n","            dash[0,i,j,t]=1\n","        else:\n","          if (i==x  and (j==N-y or j== N-y-1) and t<th):\n","            dash[1,i,j,t]=1\n","    if t==th:\n","      th+=th0\n","      y+=2\n","\n","  return dash\n","\n","\n","testSet = IBMGestureDataset(datasetPath  =  '/content/Test/', \n","                              sampleFile  ='/content/Test/test.txt',\n","                              samplingTime=1.0,\n","                              sampleLength=1450)\n","testLoader = DataLoader(dataset=testSet, batch_size=1, shuffle=False, num_workers=4)\n","\n","\n","#samples = [i for i in range(264)]\n","samples = [0,178]\n","stats.testing.reset()\n","\n","N=128\n","flag=0\n","left = 1\n","min_x=0\n","x=min_x\n","y=2\n","th0=250\n","start=time.time()\n","while samples and min_x<12:\n","  temp= list(samples)\n","  corner= dashGen(y,x,left,th0)\n","  for i  in temp:\n","\n","    input,target,label=testSet[i]\n","    \n","    adv= torch.clamp(input.unsqueeze(dim=0)+corner,0,1)\n","    with torch.no_grad():\n","      adv  = adv.to(device)\n","      target = target.to(device) \n","\n","    output = net.forward(adv)\n","    if (snn.predict.getClass(output) != label):\n","      #print(f' Sample {i} , {label}')\n","      try: \n","        samples.remove(i)\n","      except:\n","        print(f'{i} not in list')\n","      # Save adversarial dataset as spike events\n","      image = torch.reshape(adv, (2,N,N,1450)).cpu().detach()\n","      TD = snn.io.spikeArrayToEvent(image.numpy(), samplingTime=1)\n","      snn.io.encodeNpSpikes(\"/content/prova/{}.npy\".format(i), TD)\n","  print(f'remaining samples {len(samples)}, x = {x}, y={y}', 'left' if left else 'right')\n","\n","  if flag:\n","    x= min_x\n","    flag^=1\n","    left^=1\n","    if left:\n","      y+=4\n","  else:\n","    x= N-1-min_x\n","    flag^=1\n","  \n","  if y>N/2:\n","    y=2\n","    min_x+=4\n","    x=min_x\n","    flag=0\n","    left = 1\n","\n","\n","print(time.time()-start)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e1grpPmF4Bqg"},"source":["#Test \n","Choose the desired Dataset (Normal, Attacked, Filtered) to verify the results."]},{"cell_type":"code","metadata":{"id":"pnl5Xu_h9LKI"},"source":["testSet = IBMGestureDataset(datasetPath  =  '/content/Test/', \n","                              sampleFile  ='/content/Test/test.txt',\n","                              samplingTime=1.0,\n","                              sampleLength=1450)\n","testLoader = DataLoader(dataset=filSet, batch_size=1, shuffle=False, num_workers=4)\n","\n","for epoch in range(1):\n","    stats.testing.reset()\n","    tSt = datetime.now()\n","    # Testing loop.\n","    for i, (input, target, label) in enumerate(testLoader, 0):\n","      net.eval()\n","      with torch.no_grad():\n","        input  = input.to(device)\n","        target = target.to(device) \n","    \n","      output = net.forward(input)\n","      stats.testing.correctSamples += torch.sum( snn.predict.getClass(output) == label ).data.item()\n","      stats.testing.numSamples     += len(label)\n","\n","      loss = error.numSpikes(output, target)\n","      stats.testing.lossSum += loss.cpu().data.item()\n","      stats.print(epoch, i)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"duq1oc3bTvHx"},"source":["# BAF\n"]},{"cell_type":"markdown","metadata":{"id":"JYZuKPiGPa5H"},"source":["##Analysis on clean input (original Dataset without perturbations)"]},{"cell_type":"code","metadata":{"id":"JF1DFnGj42Mq"},"source":["import numpy as np\n","\n","def update(x,y,t,A,s):\n","  for i in range(x-s,x+s+1):\n","     for j in range(y-s,y+s+1):\n","        if not(i==x and j==y) and i>0 and j>0 and i<128 and j<128:\n","\t        A[i][j] = t\n","\n","testSet = IBMGestureDataset(datasetPath  =  '/content/Test/', \n","                              sampleFile  ='/content/Test/test.txt',\n","                              samplingTime=1.0,\n","                              sampleLength=1450)\n","testLoader = DataLoader(dataset=testSet, batch_size=1, shuffle=False, num_workers=4)\n","\n","for s in [1,2,3,4]:\n","  stats1 = snn.utils.stats()\n","  stats5 = snn.utils.stats()\n","  stats10 = snn.utils.stats()\n","  stats20 = snn.utils.stats()          \n","\n","  for i in range(264):     \n","    input,target,label = testSet[i]    \n","    data= np.load('/content/Test/{}.npy'.format(i))\n","    data= data[data[:,3].argsort()] #sort elements by timestamp\n","    temp=np.zeros((128,128))\n","    real1=[]\n","    real5=[]\n","    real10=[]\n","    real20=[]\n","    for d in data:\n","      update(int(d[0]),int(d[1]),d[3],temp,s)\n","      if d[3]-temp[int(d[0])][int(d[1])]<1:\n","        real1.append(d)\n","\n","      if d[3]-temp[int(d[0])][int(d[1])]<5:\n","        real5.append(d)   \n","\n","      if d[3]-temp[int(d[0])][int(d[1])]<10:\n","        real10.append(d)\n","\n","      if d[3]-temp[int(d[0])][int(d[1])]<20:\n","        real20.append(d)  \n","\n","    real1=np.stack(real1, axis=0 )\n","    with open(\"/content/filtro/1.npy\", \"wb\") as f:\n","      np.save(f,real1)\n","    input1 = snn.io.readNpSpikes(\n","        \"/content/filtro/1.npy\").toSpikeTensor(torch.zeros((2,128,128,1450)), samplingTime=1.0)\n","    input1 =  input1.to(device)\n","    output1 = net.forward(torch.unsqueeze(input1,dim=0))\n","    stats1.testing.correctSamples += torch.sum( snn.predict.getClass(output1) == label ).data.item()\n","    stats1.testing.numSamples     += 1\n","    #stats1.print(1,i)\n","\n","    real5=np.stack(real5, axis=0 )\n","    with open(\"/content/filtro/5.npy\", \"wb\") as f:\n","      np.save(f,real5)\n","    input5 = snn.io.readNpSpikes(\n","        \"/content/filtro/5.npy\").toSpikeTensor(torch.zeros((2,128,128,1450)), samplingTime=1.0)\n","    input5 =  input5.to(device)\n","    output5 = net.forward(torch.unsqueeze(input5,dim=0))\n","    stats5.testing.correctSamples += torch.sum( snn.predict.getClass(output5) == label ).data.item()\n","    stats5.testing.numSamples     += 1\n","    #stats5.print(1,i)\n","\n","    real10=np.stack(real10, axis=0 )\n","    with open(\"/content/filtro/10.npy\", \"wb\") as f:\n","      np.save(f,real10)\n","    input10 = snn.io.readNpSpikes(\n","        \"/content/filtro/10.npy\").toSpikeTensor(torch.zeros((2,128,128,1450)), samplingTime=1.0)\n","    input10 =  input10.to(device)\n","    output10 = net.forward(torch.unsqueeze(input10,dim=0))\n","    stats10.testing.correctSamples += torch.sum( snn.predict.getClass(output10) == label ).data.item()\n","    stats10.testing.numSamples     += 1\n","    #stats10.print(1,i)    \n","\n","    real20=np.stack(real20, axis=0 )\n","    with open(\"/content/filtro/20.npy\", \"wb\") as f:\n","      np.save(f,real20)\n","    input20= snn.io.readNpSpikes(\n","        \"/content/filtro/20.npy\").toSpikeTensor(torch.zeros((2,128,128,1450)), samplingTime=1.0)\n","    input20 =  input20.to(device)\n","    output20 = net.forward(torch.unsqueeze(input20,dim=0))\n","    stats20.testing.correctSamples += torch.sum( snn.predict.getClass(output20) == label ).data.item()\n","    stats20.testing.numSamples     += 1\n","  stats1.print(1,i)\n","  stats5.print(1,i)\n","  stats10.print(1,i)\n","  stats20.print(1,i)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JGZvJeE-Q6D0"},"source":["##Adversarial examples tested on the SNN, after being filtered by several BAFs"]},{"cell_type":"code","metadata":{"id":"YI5L9FJTTvH1"},"source":["import numpy as np\n","\n","def update(x,y,t,A,s):\n","  for i in range(x-s,x+s+1):\n","     for j in range(y-s,y+s+1):\n","        if not(i==x and j==y) and i>=0 and j>=0 and i<128 and j<128:\n","\t        A[i][j] = t\n","\n","stats1 = snn.utils.stats()\n","stats5 = snn.utils.stats()\n","stats10 = snn.utils.stats()\n","stats20 = snn.utils.stats()          \n","for s in [1,2,3]:\n","  for i in range(264):     \n","    input,target,label = advSet[i]    \n","    data= np.load('/content/prova/{}.npy'.format(i))\n","    data= data[data[:,3].argsort()] #sort elements by timestamp\n","    temp=np.zeros((128,128))\n","    real1=[]\n","    real5=[]\n","    real10=[]\n","    real20=[]\n","    for d in data:\n","      update(int(d[0]),int(d[1]),d[3],temp,s)\n","      if d[3]-temp[int(d[0])][int(d[1])]<1:\n","        real1.append(d)\n","\n","      if d[3]-temp[int(d[0])][int(d[1])]<5:\n","        real5.append(d)   \n","\n","      if d[3]-temp[int(d[0])][int(d[1])]<10:\n","        real10.append(d)\n","\n","      if d[3]-temp[int(d[0])][int(d[1])]<20:\n","        real20.append(d)  \n","\n","    real1=np.stack(real1, axis=0 )\n","    with open(\"/content/filtro/1.npy\", \"wb\") as f:\n","      np.save(f,real1)\n","    input1 = snn.io.readNpSpikes(\n","        \"/content/filtro/1.npy\").toSpikeTensor(torch.zeros((2,128,128,1450)), samplingTime=1.0)\n","    input1 =  input1.to(device)\n","    output1 = net.forward(torch.unsqueeze(input1,dim=0))\n","    stats1.testing.correctSamples += torch.sum( snn.predict.getClass(output1) == label ).data.item()\n","    stats1.testing.numSamples     += 1\n","    stats1.print(1,i)\n","\n","    real5=np.stack(real5, axis=0 )\n","    with open(\"/content/filtro/5.npy\", \"wb\") as f:\n","      np.save(f,real5)\n","    input5 = snn.io.readNpSpikes(\n","        \"/content/filtro/5.npy\").toSpikeTensor(torch.zeros((2,128,128,1450)), samplingTime=1.0)\n","    input5 =  input5.to(device)\n","    output5 = net.forward(torch.unsqueeze(input5,dim=0))\n","    stats5.testing.correctSamples += torch.sum( snn.predict.getClass(output5) == label ).data.item()\n","    stats5.testing.numSamples     += 1\n","    stats5.print(1,i)\n","\n","    real10=np.stack(real10, axis=0 )\n","    with open(\"/content/filtro/10.npy\", \"wb\") as f:\n","      np.save(f,real10)\n","    input10 = snn.io.readNpSpikes(\n","        \"/content/filtro/10.npy\").toSpikeTensor(torch.zeros((2,128,128,1450)), samplingTime=1.0)\n","    input10 =  input10.to(device)\n","    output10 = net.forward(torch.unsqueeze(input10,dim=0))\n","    stats10.testing.correctSamples += torch.sum( snn.predict.getClass(output10) == label ).data.item()\n","    stats10.testing.numSamples     += 1\n","    stats10.print(1,i)    \n","\n","    real20=np.stack(real20, axis=0 )\n","    with open(\"/content/filtro/20.npy\", \"wb\") as f:\n","      np.save(f,real20)\n","    input20= snn.io.readNpSpikes(\n","        \"/content/filtro/20.npy\").toSpikeTensor(torch.zeros((2,128,128,1450)), samplingTime=1.0)\n","    input20 =  input20.to(device)\n","    output20 = net.forward(torch.unsqueeze(input20,dim=0))\n","    stats20.testing.correctSamples += torch.sum( snn.predict.getClass(output20) == label ).data.item()\n","    stats20.testing.numSamples     += 1\n","    stats20.print(1,i)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IipMla4tnhgA"},"source":["# Mask Filter"]},{"cell_type":"markdown","metadata":{"id":"mkbQLPIt4k7g"},"source":["##Analysis on clean input (original Dataset without perturbations)"]},{"cell_type":"code","metadata":{"id":"EFf00fK24qMr"},"source":["testSet = IBMGestureDataset(datasetPath  =  '/content/Test/', \n","                              sampleFile  ='/content/Test/test.txt',\n","                              samplingTime=1.0,\n","                              sampleLength=1450)\n","\n","stats.testing.reset()\n","tSt = datetime.now()\n","th = [25,50,75,100,125,150,175,200]\n","for T in th:\n","  for i in range(264):\n","    input, target, label = testSet[i]\n","    activity= torch.sum(input, dim=3)\n","    activity= torch.sum(activity, dim=0)\n","    mask=torch.where((activity>T),0,1)\n","    mask=mask.expand(2,128,128)\n","    inp= input[:,:,:,:]*mask.unsqueeze(dim=3)\n","    net.eval()\n","    with torch.no_grad():\n","      inp  = inp.to(device)\n","      target = target.to(device) \n","\n","    output = net.forward(torch.unsqueeze(inp,dim=0))\n","    stats.testing.correctSamples += torch.sum( snn.predict.getClass(output) == label ).data.item()\n","    stats.testing.numSamples     += 1\n","\n","    stats.print(1,i)\n","  MF = stats.testing.accuracy()\n","  print(T,MF)\n","\n","\n","\t\t\t\t\t\n","     \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eSNvcA-z4eXg"},"source":["##Adversarial examples tested on the SNN, after being filtered by several MFS"]},{"cell_type":"code","metadata":{"id":"FPd5fdNqAk1H"},"source":["advSet = IBMGestureDataset(datasetPath  =  '/content/prova/', \n","                              sampleFile  ='/content/Test/test.txt',\n","                              samplingTime=1.0,\n","                              sampleLength=1450)\n","advLoader = DataLoader(dataset=advSet, batch_size=1, shuffle=False, num_workers=4)\n","\n","th = [25,50,75,100,125,150,175,200]\n","for T in th:\n","  stats.testing.reset()\n","  tSt = datetime.now()\n","  for i in range(264):\n","    input, target, label = advSet[i]\n","    activity= torch.sum(input, dim=3)\n","    activity= torch.sum(activity, dim=0)\n","    mask=torch.where((activity>T),0,1)\n","    mask=mask.expand(2,128,128)\n","    inp= input[:,:,:,:]*mask.unsqueeze(dim=3)\n","    net.eval()\n","    with torch.no_grad():\n","      inp  = inp.to(device)\n","      target = target.to(device) \n","\n","    output = net.forward(torch.unsqueeze(inp,dim=0))\n","    stats.testing.correctSamples += torch.sum( snn.predict.getClass(output) == label ).data.item()\n","    stats.testing.numSamples     += 1\n","\n","    stats.print(1,i)\n","  MF = stats.testing.accuracy()\n","  print(T,MF)\n","\n","\n","\t\t\t\t\t\n","     \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o_ZWLMTlnhgA"},"source":["# VISUALIZE"]},{"cell_type":"code","metadata":{"id":"sq71TxwYnhgA"},"source":["# Visualize the input spikes (first five samples).\n","testSet = IBMGestureDataset(datasetPath  =  '/content/Test/', \n","                              sampleFile  ='/content/Test/test.txt',\n","                              samplingTime=1.0,\n","                              sampleLength=1450)\n","\n","from IPython.display import HTML\n","for i in range(1):\n","    input, target, label = testSet[i]\n","    snn.io.showTD(snn.io.spikeArrayToEvent(input.reshape((2, 128, 128, -1)).cpu().data.numpy()))\n","anim = snn.io.animTD(snn.io.spikeArrayToEvent(input.reshape((2, 128, 128, -1)).cpu().data.numpy()))\n","HTML(anim.to_jshtml())\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Hze_ZxsMTBN"},"source":["#Normal noise injection + BAF"]},{"cell_type":"code","metadata":{"id":"ZELKPdiM9bOi"},"source":["def update(x,y,t,A,s):\n","  for i in range(x-s,x+s+1):\n","     for j in range(y-s,y+s+1):\n","        if not(i==x and j==y) and i>0 and j>0 and i<127 and j<127:\n","\t        A[i][j] = t\n","\n","np.random.seed(7)\n","mask = np.where(np.random.uniform(size=(1,2,128,128,1450))<0.01,1,0)\n","np.random.seed(1)\n","normal = np.random.normal(size=(1,2,128,128,1450))\n","noise= torch.Tensor(mask*abs(normal))\n","amp=[1 ,0.85, 0.70, 0.55, 0.40, 0.25, 0.10]\n","for a in amp:\n","  net.eval()\n","  stats.testing.reset()\n","  tSt = datetime.now()\n","  print(tSt,a)\n","  # Testing loop.\n","  for i, (input, target, label) in enumerate(testLoader, 0):\n","    input= torch.clamp(input+a*noise,0,1)\n","    #print(i)\n","    input=torch.reshape(input,(1450,128,128,2))\n","    index=np.nonzero(input)\n","    temp= np.zeros((128,128))\n","    for i in index.numpy():\n","      update(i[1],i[2],i[0],temp)\n","      if i[0]-temp[i[1]][i[2]]>=5:\n","        input[i[0],i[1],i[2],i[3]]= 0.\n","    with torch.no_grad():\n","      input  = input.to(device)\n","      target = target.to(device)\n","    input=torch.reshape(input,(1,2,128,128,1450))\n","    output = net.forward(input)\n","    # Stats updating\t\t\n","    stats.testing.correctSamples += torch.sum(snn.predict.getClass(output) == label).data.item()\n","    stats.testing.numSamples     += len(label)\n","    loss = error.numSpikes(output, target)\n","    stats.testing.lossSum += loss.cpu().data.item()\n","  tEnd=datetime.now()\n","  print(tEnd)\n","  print(a,stats.testing.accuracy())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HG9jaRtt6T4K"},"source":["#Normal noise injection + MF"]},{"cell_type":"code","metadata":{"id":"1IXhZ2-26T4K"},"source":["np.random.seed(7)\n","mask = np.where(np.random.uniform(size=(1,2,128,128,1450))<0.01,1,0)\n","np.random.seed(1)\n","normal = np.random.normal(size=(1,2,128,128,1450))\n","noise= torch.Tensor(mask*abs(normal))\n","amp=[1 ,0.85, 0.70, 0.55, 0.40, 0.25, 0.10]\n","th = [25,50,75,100,125,150,175,200]\n","for T in th:\n","  for a in amp:\n","    net.eval()\n","    stats.testing.reset()\n","    tSt = datetime.now()\n","    print(tSt,a)\n","    # Testing loop.\n","    for i, (input, target, label) in enumerate(testLoader, 0):\n","      input= torch.clamp(input+a*noise,0,1)\n","      activity= torch.sum(input, dim=3)\n","      activity= torch.sum(activity, dim=0)\n","      mask=torch.where((activity>T),0,1)\n","      mask=mask.expand(2,128,128)\n","      inp= input[:,:,:,:]*mask.unsqueeze(dim=3)\n","      net.eval()\n","      with torch.no_grad():\n","        inp  = inp.to(device)\n","        target = target.to(device) \n","\n","      output = net.forward(torch.unsqueeze(inp,dim=0))\n","      stats.testing.correctSamples += torch.sum( snn.predict.getClass(output) == label ).data.item()\n","      stats.testing.numSamples     += 1\n","\n","      stats.print(1,i)\n","    MF = stats.testing.accuracy()\n","    print(T,a,MF)"],"execution_count":null,"outputs":[]}]}